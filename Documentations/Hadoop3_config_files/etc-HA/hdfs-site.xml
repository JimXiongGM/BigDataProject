<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
        <description>Indicates how many times data is replicated in the cluster.</description>
        <!-- Don't enter a value higher than the actual number of slave nodes -->
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/data/hadoop/hdfs/datanode</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/data/hadoop/hdfs/namenode</value>
    </property>
    <property>
        <name>dfs.namenode.http-address</name>
        <value>master:50070</value> <!-- Default value in Hadoop 3.1.1 is 0.0.0.0:9870 -->
        <description>The address and the base port where the dfs namenode web ui will listen on.</description>
    </property>


<!-- HA mode add -->
    <property>
        <name>dfs.nameservices</name>
        <value>xgmcluster</value>
        <description>the cluster name</description>
    </property>

    <property>
        <name>dfs.ha.namenodes.xgmcluster</name>
        <value>master,slave1</value> 
        <description>HA mode needs two nodes</description>
    </property>
<!-- RPC通信地址  -->  
    <property>
        <name>dfs.namenode.rpc-address.xgmcluster.master</name>
        <value>master:8020</value> 
    </property>

    <property>
        <name>dfs.namenode.rpc-address.xgmcluster.slave1</name>
        <value>slave1:8020</value> 
    </property>
<!-- HTTP通信地址  -->
    <property>
        <name>dfs.namenode.http-address.xgmcluster.master</name>
        <value>master:50070</value> 
    </property>  

    <property>
        <name>dfs.namenode.http-address.xgmcluster.slave1</name>
        <value>slave1:50070</value> 
    </property>    

<!-- 指定NameNode的元数据在JournalNode日志上的存放位置(一般和zookeeper部署在一起) -->  
    <property>  
        <name>dfs.namenode.shared.edits.dir</name>  
        <value>qjournal://master:8485;slave1:8485;slave2:8485;slave3:8485/xgmcluster</value>  
    </property>  

<!--客户端通过代理访问namenode，访问文件系统，HDFS客户端与Active节点通信的Java类，使用其确定Active节点是否活跃  -->  
    <property>  
        <name>dfs.client.failover.proxy.provider.xgmcluster</name>  
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>  
    </property>

<!--杀死进程-->  
    <property>  
        <name>dfs.ha.fencing.methods</name>  
        <value>sshfence</value> 
    </property>  
<!-- 这个是使用sshfence隔离机制时才需要配置ssh免登陆 -->  
    <property>  
        <name>dfs.ha.fencing.ssh.private-key-files</name>  
        <value>/.ssh/id_rsa</value>  
    </property>

<!-- 指定JournalNode在本地磁盘存放数据的位置 -->  
    <property>  
        <name>dfs.journalnode.edits.dir</name>  
        <value>/data/hadoop/hdfs/jn</value>  
    </property> 

<!-- 自动failover -->  

    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>

<!-- 指定zookeeper地址 -->



</configuration>
